{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands on session: Autoencoders (2)\n",
    "This is the second of two examples, where we will use Autoencoders to reduce the dimensionality of the calcium imaging data. We will now use a different dataset, which contains the spike times points of >100 neurons along with the behavioral data of a mouse.\n",
    "\n",
    "In this example, we encode the calcium data for each time point, i.e., we represent the activity of all neurons (neuron population response) at each time point in a lower-dimensional space. This is different from the previous example, where we represented the activity of each neuron in a lower-dimensional space, compressing the time information. \n",
    "\n",
    "This exercise refers to [Chapter 8 \"Autoencoders\"](https://www.fabriziomusacchio.com/teaching/teaching_dimensionality_reduction_in_neuroscience/08_autoencoders) of the \"[Dimensionality reduction in neuroscience](https://www.fabriziomusacchio.com/teaching/teaching_dimensionality_reduction_in_neuroscience/)\" course (tutor: Fabrizio Musacchio, Oct 17, 2024)\n",
    "\n",
    "## Acknowledgements\n",
    "The dataset used here is extracted from the datasets available in the [CEBRA package](https://cebra.ai/docs/demo_notebooks/Demo_hippocampus.html).\n",
    "\n",
    "## Dataset\n",
    "The dataset consists of several sub-structures:\n",
    "- `neuron_spike_times`: A binary matrix of shape `(N_rec, n_timepoints)` where `N_rec=120` is the number of\n",
    "    recorded neurons and `n_timepoints=1000` is the number of timepoints in the recording. A value of 1 indicates\n",
    "    a spike from a neuron at a given timepoint.\n",
    "- `position_readout`: A vector of shape `(n_timepoints)`, representing the position of the mouse at each timepoint.\n",
    "- `left_direction`: A binary vector of shape `(n_timepoints)`, indicating whether the mouse is moving in the left direction.\n",
    "- `right_direction`: A binary vector of shape `(n_timepoints)`, indicating whether the mouse is moving in the right direction.\n",
    "- `N_rec`: The number of recorded neurons.\n",
    "\n",
    "## Environment setup\n",
    "For reproducibility:\n",
    "\n",
    "```bash\n",
    "conda create -n dimredcution python=3.11 mamba -y\n",
    "conda activate dimredcution\n",
    "mamba install ipykernel matplotlib numpy scipy scikit-learn -y\n",
    "mamba install pytorch torchvision -c pytorch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% IMPORTS\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "from scipy.io import loadmat\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import Subset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# verify torch version and GPU availability:\n",
    "print(f\"torch backend MPS is available? {torch.backends.mps.is_available()}\")\n",
    "print(f\"current PyTorch installation built with MPS activated? {torch.backends.mps.is_built()}\")\n",
    "print(f\"check the torch MPS backend: {torch.device('mps')}\")\n",
    "print(f\"test torch tensor on MPS: {torch.tensor([1,2,3], device='mps')}\")\n",
    "\"\"\" \n",
    "On macOS: Don't forget to move your model to the MPS device, if you want to use it:\n",
    "\n",
    "device = torch.device('mps')\n",
    "model = model.to(device)\n",
    "\"\"\"\n",
    "\n",
    "# set global properties for all plots:\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.rcParams[\"axes.spines.top\"]    = False\n",
    "plt.rcParams[\"axes.spines.bottom\"] = False\n",
    "plt.rcParams[\"axes.spines.left\"]   = False\n",
    "plt.rcParams[\"axes.spines.right\"]  = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the path to the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "DATA_FILENAME = 'hippocampus_achilles_from_cebra_dict.pkl'\n",
    "DATA_FILE = os.path.join(DATA_PATH, DATA_FILENAME)\n",
    "\n",
    "RESULTSPATH = '../results/'\n",
    "# check whether the results path exists, if not, create it:\n",
    "if not os.path.exists(RESULTSPATH):\n",
    "    os.makedirs(RESULTSPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hippocampus_achilles_dict = pickle.load(open(DATA_FILE, 'rb'))\n",
    "\n",
    "neuron_spike_times = hippocampus_achilles_dict['neuron_spike_times']\n",
    "position_readout   = hippocampus_achilles_dict['position_readout']\n",
    "left_direction     = hippocampus_achilles_dict['left_direction']\n",
    "right_direction    = hippocampus_achilles_dict['right_direction']\n",
    "N_rec              = hippocampus_achilles_dict['N_rec']\n",
    "n_timepoints       = neuron_spike_times.shape[1]\n",
    "\n",
    "# extract the neurons and timepoints for the scatter plot:\n",
    "neurons, timepoints = np.where(neuron_spike_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spike raster plot and histogram of spiking rate:\n",
    "fig = plt.figure(figsize=(6, 8))\n",
    "gs = gridspec.GridSpec(6, 1)\n",
    "\n",
    "# create the first subplot (3/4 of the figure)\n",
    "ax1 = plt.subplot(gs[0:4, :])\n",
    "ax1.scatter(timepoints, neurons, s=8.0, color='mediumaquamarine', alpha=1.0)\n",
    "#ax1.imshow(neuron_spike_times, aspect='auto', cmap='viridis', interpolation='none')\n",
    "plt.title(f\"1st {n_timepoints} timepoints of the hippocampus\\ndataset 'achilles' from CEBRA\")\n",
    "#ax1.set_xlabel(\"time [ms]\")\n",
    "ax1.set_xticks([])\n",
    "ax1.set_ylabel(\"neuron ID\")\n",
    "\n",
    "# create the second subplot:\n",
    "ax2 = plt.subplot(gs[4, :])\n",
    "hist_binwidth = 5.0\n",
    "t_bins = np.arange(np.amin(timepoints), np.amax(timepoints), hist_binwidth)\n",
    "n, bins = np.histogram(timepoints, bins=t_bins)\n",
    "heights = 1000 * n / (hist_binwidth * (N_rec))\n",
    "ax2.bar(t_bins[:-1], heights, width=hist_binwidth, color='violet')\n",
    "ax2.set_ylabel(\"firing rate\\n[Hz]\")\n",
    "ax2.set_xticks([])\n",
    "\n",
    "# create the third subplot:\n",
    "ax3 = plt.subplot(gs[5, :])\n",
    "#ax3.plot(np.arange(1000), position_readout, c = 'k')\n",
    "ax3.scatter(np.arange(n_timepoints)[left_direction == 1],  position_readout[left_direction == 1], \n",
    "         c='lightseagreen', label='left direction', s=1)\n",
    "ax3.scatter(np.arange(n_timepoints)[right_direction == 1], position_readout[right_direction == 1], \n",
    "         c='salmon', label='right direction', s=1)\n",
    "ax3.set_ylabel(f'position\\n[m]')\n",
    "ax3.set_xlabel(\"time [s]\")\n",
    "ax3.legend(loc=\"upper right\", frameon=True)\n",
    "ax3.set_xticks(np.arange(0, n_timepoints+1, 200))\n",
    "ax3.set_xticklabels(np.arange(0, 0.025*n_timepoints+1, 0.025*200).astype(\"int\")) \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTSPATH, 'AE_behavior_hippocampus_achilles_spike_raster.png'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to rearange the data. This time, we need to **feed both neural spike times and position readout** into the autoencoder. This means concatenating the two data types into a single input vector for the AE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate neural data and position readout:\n",
    "neuron_spike_times_flat = neuron_spike_times.T  # shape: (timepoints, neurons)\n",
    "position_readout_flat   = position_readout.reshape(-1, 1)  # reshape to (timepoints, 1)\n",
    "\n",
    "# concatenate along the feature axis (columns):\n",
    "combined_data = np.hstack((neuron_spike_times_flat, position_readout_flat))\n",
    "\n",
    "print(f\"Combined data shape: {combined_data.shape}\")  # should be (timepoints, neurons + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again define a custom dataset class for PyTorch' DataLoader. The `CustomDataset` class needs to be modified to include both the neural spike times and the behavior data as inputs for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]  # Number of timepoints\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        instance = self.data[idx, :]  # Return the combined data for the given timepoint\n",
    "        sample = {\"data\": instance}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the combined data to a tensor and apply the `CustomDataset` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the combined data to a tensor\n",
    "combined_data_tensor = torch.tensor(combined_data).float()\n",
    "\n",
    "# apply the CustomDataset class to the combined data tensor:\n",
    "combined_dataset_tensor = CustomDataset(combined_data_tensor)\n",
    "\n",
    "# check the dimensions:\n",
    "print(f\"Dataset shape: {combined_dataset_tensor.__getitem__(0)['data'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split the dataset into training (90%) and test (10%) sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the training (90%) and testing set sizes (10%):\n",
    "train_size = int(np.floor(0.9 * len(combined_dataset_tensor)))\n",
    "test_size  = len(combined_dataset_tensor) - train_size\n",
    "\n",
    "# create subsets for training and testing:\n",
    "train_indices, test_indices = torch.utils.data.random_split(range(len(combined_dataset_tensor)), [train_size, test_size])\n",
    "\n",
    "train_dataset = Subset(combined_dataset_tensor, train_indices)\n",
    "test_dataset  = Subset(combined_dataset_tensor, test_indices)\n",
    "\n",
    "# create DataLoaders for the training and testing sets:\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=150, shuffle=True)\n",
    "test_loader  = DataLoader(dataset=test_dataset, batch_size=150, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 Define the Autoencoder\n",
    "We need to redefine the Autoencoder class from the previous exercise to include the concatenated neural and behavioral data. Also the input size has changed: If the neural data has `N_rec` neurons and ?n_timepoints? timepoints, and the position data is 1-dimensional, then the input size will be `N_rec+1`.\n",
    "\n",
    "1. Create an Autoencoder class, e.g., called `TemporalAutoencoder` that inherits from `nn.Module`.\n",
    "2. Create an `encoder` with the following layers:\n",
    "    - A linear layer with input size `input_size` and output size `64`.\n",
    "    - A ReLU activation function.\n",
    "    - A linear layer with input size `64` and output size `32`.\n",
    "    - A ReLU activation function.\n",
    "    - A linear layer with input size `32` and output size `latent_size`, where `latent_size` is the definable latent space dimension.\n",
    "3. Create an according `decoder`.\n",
    "4. Define the `forward` pass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here:\n",
    "\n",
    "#class TemporalAutoencoder(...):\n",
    "#    def __init__(self, input_size, latent_size):\n",
    "#        super().__init__()\n",
    "#        \n",
    "        # Encoder: \n",
    "#        self.encoder = torch.nn.Sequential(\n",
    "#            ...\n",
    "#        )\n",
    "#        \n",
    "        # Decoder: reconstruct the original neural activity from latent space\n",
    "#        self.decoder = torch.nn.Sequential(\n",
    "#            ...\n",
    "#        )\n",
    "#        \n",
    "#    def forward(self, x):\n",
    "#        ...\n",
    "#        return latent, reconstructed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝  Create the autoencoder with the appropriate input size\n",
    "1. The input size is the number of neurons plus one (for the position data). Hint: You can extract it from the combined data tensor.\n",
    "2. Define the latent space dimension `latent_size=3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here:\n",
    "\n",
    "# input_size  = ...\n",
    "# latent_size = ... \n",
    "# model = TemporalAutoencoder(...)\n",
    "\n",
    "# move the model to the MPS device\n",
    "# device = torch.device('mps')\n",
    "# model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝  Train the autoencoder\n",
    "The training loop remains largely the same. The loss function (MSELoss) will now compute the reconstruction error over both the neural and behavioral data.\n",
    "\n",
    "Prepare and create a training loop to train the autoencoder on the training data:\n",
    "1. Train the autoencoder for 250 epochs.\n",
    "2. Keep track of the training and validation losses.\n",
    "3. As loss function, use the Mean Squared Error (MSE) loss (`torch.nn.MSELoss()`).\n",
    "4. Use the Adam optimizer (`torch.optim.Adam(...)`) with an initial learning rate of 1e-2, a `weight_decay` of 1e-8 and a `step_size` of 1.\n",
    "5. Follow further instructions below to complete the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here:\n",
    "\n",
    "# set the training parameters:\n",
    "# epochs       = 249\n",
    "\n",
    "# prepare lists to store the training and validation losses\n",
    "# train_losses = []\n",
    "# val_losses   = []\n",
    "\n",
    "# define the loss function and optimizer:\n",
    "# loss_function = ...\n",
    "# learning_rate = 1e-3\n",
    "# optimizer = torch.optim.Adam(...)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=1, gamma=0.98)\n",
    "\n",
    "#for epoch in range(epochs):\n",
    "#    model.train()\n",
    "#    train_loss = 0.0\n",
    "#    for batch in train_loader:\n",
    "#        batch_data = batch['data'].to(device)\n",
    "#        \n",
    "        # STEP 1: Forward pass\n",
    "#        latent, reconstructed = ...\n",
    "        \n",
    "        # STEP 2: Compute loss\n",
    "#        loss = ...\n",
    "        \n",
    "        # backpropagation and optimization (just uncomment the following lines)\n",
    "#        optimizer.zero_grad()\n",
    "#        loss.backward()\n",
    "#       optimizer.step()\n",
    "        \n",
    "        # add the loss to the training loss\n",
    "        # train_loss += ...\n",
    "    \n",
    "    # average training loss: (just uncomment the following line)\n",
    "    #avg_train_loss = train_loss / len(train_loader)\n",
    "    #train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Validation phase:\n",
    "    # model.eval()\n",
    "    # val_loss = 0.0\n",
    "#    with torch.no_grad():\n",
    "#        for val_batch in test_loader:\n",
    "#            val_batch_data = ...\n",
    "#            latent_val, reconstructed_val = ...\n",
    "#            val_loss += ...\n",
    "    \n",
    "    # just uncomment the following lines:\n",
    "#    avg_val_loss = val_loss / len(test_loader)\n",
    "#    val_losses.append(avg_val_loss)\n",
    "#    \n",
    "#    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 Assess the loss curves\n",
    "1. Plot the training and validation loss curves (i.e., your previously stored losses).\n",
    "2. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we extract the AE latent space representation from the full dataset (instead of the training set only):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract latent space representation from the full dataset\n",
    "model.eval()\n",
    "latent_space = []\n",
    "with torch.no_grad():\n",
    "    for batch in DataLoader(dataset=combined_dataset_tensor, batch_size=128, shuffle=False):\n",
    "        batch_data = batch['data'].to(device)\n",
    "        latent, _ = model(batch_data)\n",
    "        latent_space.append(latent.cpu().numpy())\n",
    "\n",
    "# concatenate latent space results:\n",
    "latent_space = np.concatenate(latent_space, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 Visualize the latent space\n",
    "1. Plot the latent space representation of the full dataset in 3D.\n",
    "2. Plot 2D projections of the latent space representation (3x, in separate plots of a subplot).\n",
    "3. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here:\n",
    "\n",
    "\n",
    "\n",
    "# Plot the 3D latent space:\n",
    "\n",
    "# Plot the 2D latent space:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 Cluster the embedded latent space variables\n",
    "1. Cluster the embedded latent space variables using KMeans with 4 clusters.\n",
    "2. Visualize the clusters in the 3D latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 Plot the behavior vector with cluster labels\n",
    "Plot the behavior vector with the cluster labels as colors and interprete the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the behavior vector, color-coded by the kmeans cluster labels:\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.scatter(np.arange(n_timepoints)[left_direction == 1],  position_readout[left_direction == 1],\n",
    "            c=kmeans_fit.labels_[left_direction == 1], cmap='viridis', label='left direction', s=1)\n",
    "plt.scatter(np.arange(n_timepoints)[right_direction == 1], position_readout[right_direction == 1],\n",
    "            c=kmeans_fit.labels_[right_direction == 1], cmap='viridis', label='right direction', s=1)\n",
    "plt.xlabel('time [s]')\n",
    "plt.ylabel('position [m]')\n",
    "plt.title('Behavior Vector Colored by KMeans Clustering')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTSPATH, f'AE_behavior_vector_kmeans_{n_clusters}_clusters.png'), dpi=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 📝 Perform a PCA for comparison\n",
    " Perform a PCA on the combined data `combined_data` and plot the results in 3D and 2D. Compare the results with the autoencoder latent space representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# perform PCA with 3 PCs for comparison:\n",
    "PCA_model = PCA(n_components=3)\n",
    "PCA_model_fit = PCA_model.fit_transform(combined_data)\n",
    "PCA_model_fit.shape\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(PCA_model_fit[:, 0], PCA_model_fit[:, 1], PCA_model_fit[:, 2], c=np.arange(len(PCA_model_fit)), cmap='viridis')\n",
    "ax.set_title(\"3D PCA of Neural Data\")\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2D PCA plot:\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(15, 6))\n",
    "ax0.scatter(PCA_model_fit[:, 0], PCA_model_fit[:, 1], c=np.arange(len(PCA_model_fit)), cmap='viridis')\n",
    "ax0.set_title(\"PC1 vs PC2\")\n",
    "ax0.set_xlabel('PC1')\n",
    "ax0.set_ylabel('PC2')\n",
    "\n",
    "ax1.scatter(PCA_model_fit[:, 0], PCA_model_fit[:, 2], c=np.arange(len(PCA_model_fit)), cmap='viridis')\n",
    "ax1.set_title(\"PC1 vs PC3\")\n",
    "ax1.set_xlabel('PC1')\n",
    "ax1.set_ylabel('PC3')\n",
    "\n",
    "ax2.scatter(PCA_model_fit[:, 1], PCA_model_fit[:, 2], c=np.arange(len(PCA_model_fit)), cmap='viridis')\n",
    "ax2.set_title(\"PC2 vs PC3\")\n",
    "ax2.set_xlabel('PC2')\n",
    "ax2.set_ylabel('PC3')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 Cluster the PCA results\n",
    "Cluster the PCA results using KMeans with 4 clusters and visualize the clusters in the 3D latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cluster the PCA space:\n",
    "n_clusters = 4\n",
    "kmeans_fit_PCA = KMeans(n_clusters=n_clusters, random_state=42).fit(PCA_model_fit)\n",
    "print(f\"unique labels: {np.unique(kmeans_fit_PCA.labels_)}\")\n",
    "\n",
    "# plot the 3D PCA space with the kmeans cluster labels:\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(PCA_model_fit[:, 0], PCA_model_fit[:, 1], PCA_model_fit[:, 2], c=kmeans_fit_PCA.labels_, cmap='viridis', marker='o', s=50,\n",
    "                        alpha=0.6)\n",
    "# add a dummy plot just for indicating cluster labels:\n",
    "for i in range(n_clusters):\n",
    "    ax.scatter([], [], [], c=plt.cm.viridis(i / (n_clusters - 1)), label=f'Cluster {i}')\n",
    "# plot the cluster centers:\n",
    "ax.scatter(kmeans_fit_PCA.cluster_centers_[:, 0], kmeans_fit_PCA.cluster_centers_[:, 1],\n",
    "              kmeans_fit_PCA.cluster_centers_[:, 2], c='red', s=100, marker='x', zorder=11, label='Cluster centers')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "plt.legend()\n",
    "plt.title('3D PCA Space with KMeans Clustering')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTSPATH, f'PCA_latent_space_kmeans_{n_clusters}_clusters.png'), dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 Plot the behavior vector color-labeled based on the PCA clusters and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the behavior vector, color-coded by the kmeans cluster labels:\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.scatter(np.arange(n_timepoints)[left_direction == 1],  position_readout[left_direction == 1],\n",
    "            c=kmeans_fit_PCA.labels_[left_direction == 1], cmap='viridis', label='left direction', s=1)\n",
    "plt.scatter(np.arange(n_timepoints)[right_direction == 1], position_readout[right_direction == 1],\n",
    "            c=kmeans_fit_PCA.labels_[right_direction == 1], cmap='viridis', label='right direction', s=1)\n",
    "plt.xlabel('time [s]')\n",
    "plt.ylabel('position [m]')\n",
    "plt.title('Behavior Vector Colored by KMeans Clustering in PCA Space')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTSPATH, f'PCA_behavior_vector_kmeans_{n_clusters}_clusters.png'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Predicting behavior from neural activity\n",
    "To further assess whether our neural data follows a hidden structure that is related to the behavior, we can test how good the data is embedded in the latent space to predict the behavior. \n",
    "\n",
    "To do so, we need to add a behavior prediction layer to the latent space of the autoencoder and we need to extend the forward pass accordingly: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderWithBehavior(nn.Module):\n",
    "    def __init__(self, input_size, latent_size, output_size):\n",
    "        super(AutoencoderWithBehavior, self).__init__()\n",
    "        \n",
    "        # Encoder: \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, latent_size)  # Latent space\n",
    "        )\n",
    "        \n",
    "        # Decoder: \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, input_size)  # Reconstruct original neural activity\n",
    "        )\n",
    "        \n",
    "        # Behavior Prediction: Predict behavior from the latent space\n",
    "        self.behavior_predictor = nn.Sequential(\n",
    "            nn.Linear(latent_size, 16),  # Use the latent space as input\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, output_size)   # Output the predicted behavior (e.g., position)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Pass input through the encoder to get the latent space\n",
    "        latent = self.encoder(x)\n",
    "        \n",
    "        # Reconstruct the original input (autoencoder output, optional)\n",
    "        reconstruction = self.decoder(latent)\n",
    "        \n",
    "        # Predict behavior from the latent space\n",
    "        predicted_behavior = self.behavior_predictor(latent)\n",
    "        \n",
    "        return latent, reconstruction, predicted_behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the model as we have done before, but now we have an additional output_size parameter for the behavior prediction, which is set to 1 in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model:\n",
    "latent_size = 3  # Latent space dimension\n",
    "output_size = 1  # predicting 1 behavior (e.g., position)\n",
    "model = AutoencoderWithBehavior(input_size=120, latent_size=latent_size, output_size=output_size).to(device)\n",
    "\n",
    "# loss functions and optimizers:\n",
    "ae_loss_function = nn.MSELoss()  # for reconstructing the input in the AE\n",
    "behavior_loss_function = nn.MSELoss()  # for predicting the behavior\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to redefine the train loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset where inputs are neural activity and targets are behavior:\n",
    "class NeuralToBehaviorDataset(Dataset):\n",
    "    def __init__(self, neural_data, behavior_data):\n",
    "        self.neural_data = neural_data  # Neural activity (2000 time frames, 120 neurons)\n",
    "        self.behavior_data = behavior_data  # Behavior data (2000 time frames, 1 behavior)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.neural_data.shape[0]  # Number of time frames\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        neural_activity = self.neural_data[idx, :]  # Neural data at time frame idx\n",
    "        behavior = self.behavior_data[idx]          # Behavior at time frame idx\n",
    "        return {\"neural_activity\": neural_activity, \"behavior\": behavior}\n",
    "\n",
    "# use the neural activity and behavior data from your existing dataset:\n",
    "neural_activity = neuron_spike_times.T  # Neural data (time points x neurons) shape: (2000, 120)\n",
    "behavior = position_readout.reshape(-1, 1)  # Behavior data, shape: (2000, 1)\n",
    "\n",
    "# convert to tensors:\n",
    "neural_activity_tensor = torch.tensor(neural_activity).float()\n",
    "behavior_tensor = torch.tensor(behavior).float()\n",
    "\n",
    "# create the dataset:\n",
    "neural_behavior_dataset = NeuralToBehaviorDataset(neural_activity_tensor, behavior_tensor)\n",
    "\n",
    "# split into training and testing sets:\n",
    "train_size = int(0.9 * len(neural_behavior_dataset))  # 90% for training\n",
    "test_size = len(neural_behavior_dataset) - train_size  # 10% for testing\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(neural_behavior_dataset, [train_size, test_size])\n",
    "\n",
    "# create DataLoaders for training and testing:\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to adjust the training loop to include the behavior prediction loss. We need to compute the behavior prediction loss and add it to the total loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop:\n",
    "epochs = 100\n",
    "train_ae_losses = []\n",
    "train_behavior_losses = []\n",
    "val_ae_losses = []\n",
    "val_behavior_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss_ae = 0.0\n",
    "    train_loss_behavior = 0.0\n",
    "    \n",
    "    # Training phase\n",
    "    for batch in train_loader:\n",
    "        neural_activity = batch['neural_activity'].to(device)\n",
    "        behavior = batch['behavior'].to(device)\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        latent, reconstructed, predicted_behavior = model(neural_activity)\n",
    "        \n",
    "        # Compute the losses\n",
    "        loss_ae = ae_loss_function(reconstructed, neural_activity)  # Autoencoder loss\n",
    "        loss_behavior = behavior_loss_function(predicted_behavior, behavior)  # Behavior prediction loss\n",
    "        \n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        total_loss = loss_ae + loss_behavior  # Sum the losses\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss_ae += loss_ae.item()\n",
    "        train_loss_behavior += loss_behavior.item()\n",
    "    \n",
    "    # Average training losses\n",
    "    train_ae_losses.append(train_loss_ae / len(train_loader))\n",
    "    train_behavior_losses.append(train_loss_behavior / len(train_loader))\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss_ae = 0.0\n",
    "    val_loss_behavior = 0.0\n",
    "    with torch.no_grad():\n",
    "        for val_batch in test_loader:\n",
    "            neural_activity_val = val_batch['neural_activity'].to(device)\n",
    "            behavior_val = val_batch['behavior'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            latent_val, reconstructed_val, predicted_behavior_val = model(neural_activity_val)\n",
    "            \n",
    "            # Compute validation losses\n",
    "            val_loss_ae += ae_loss_function(reconstructed_val, neural_activity_val).item()\n",
    "            val_loss_behavior += behavior_loss_function(predicted_behavior_val, behavior_val).item()\n",
    "    \n",
    "    # Average validation losses\n",
    "    val_ae_losses.append(val_loss_ae / len(test_loader))\n",
    "    val_behavior_losses.append(val_loss_behavior / len(test_loader))\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{epochs}, Train AE Loss: {train_ae_losses[-1]:.6f}, Train Behavior Loss: {train_behavior_losses[-1]:.6f}, '\n",
    "          f'Val AE Loss: {val_ae_losses[-1]:.6f}, Val Behavior Loss: {val_behavior_losses[-1]:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 Plot the training and validation loss curves\n",
    "1. Plot the training and validation losses for the autoencoder.\n",
    "2. Plot the training and validation losses for the behavior prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we again extract the latent space representation from the full dataset to plot it in the 3D latent space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on the full dataset:\n",
    "full_loader = DataLoader(dataset=neural_behavior_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# collect predictions and actuals for the entire dataset:\n",
    "model.eval()\n",
    "full_predictions = []\n",
    "full_actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in full_loader:\n",
    "        neural_activity = batch['neural_activity'].to(device)\n",
    "        behavior = batch['behavior'].to(device)\n",
    "        \n",
    "        # Get predictions\n",
    "        _, _, predicted_behavior = model(neural_activity)\n",
    "        \n",
    "        # Append the predictions and actuals\n",
    "        full_predictions.append(predicted_behavior.cpu().numpy())\n",
    "        full_actuals.append(behavior.cpu().numpy())\n",
    "\n",
    "# concatenate predictions and actuals for the full dataset:\n",
    "full_predictions = np.concatenate(full_predictions, axis=0)\n",
    "full_actuals = np.concatenate(full_actuals, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 Plot the actual vs. predicted behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dimredcution",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
