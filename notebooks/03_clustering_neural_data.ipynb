{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands on session: Clustering methods\n",
    "In this example, we will use various clustering techniques to cluster dimensional reduced (PCA) neuronal data. Here, we will use kmeans clustering, agglomerative clustering, and DBSCAN.\n",
    "\n",
    "This exercise refers to [Chapter 3 \"Clustering methods\"](https://www.fabriziomusacchio.com/teaching/teaching_dimensionality_reduction_in_neuroscience/03_clustering) of the \"[Dimensionality reduction in neuroscience](https://www.fabriziomusacchio.com/teaching/teaching_dimensionality_reduction_in_neuroscience/)\" course (tutor: Fabrizio Musacchio, Oct 17, 2024)\n",
    "\n",
    "## Acknowledgements\n",
    "The dataset is from the 2023's course 'data analysis techniques in neuroscience' by the Chen Institute for Neuroscience at Caltech:  \n",
    "\n",
    "<https://github.com/cheninstitutecaltech/Caltech_DATASAI_Neuroscience_23>\n",
    "\n",
    "and originally from the paper:\n",
    "\n",
    "Remedios, R., Kennedy, A., Zelikowsky, M. et al. Social behaviour shapes hypothalamic neural  ensemble representations of conspecific sex. Nature 550, 388–392 (2017). <https://doi.org/10.1038/nature23885>\n",
    "\n",
    "## Dataset\n",
    "We will work with the same calcium imaging data from the previous exercise (PCA). For details, please refer to the previous exercise.\n",
    "\n",
    "## Environment setup\n",
    "For reproducibility:\n",
    "\n",
    "```bash\n",
    "conda create -n dimredcution python=3.11 mamba -y\n",
    "conda activate dimredcution\n",
    "mamba install ipykernel matplotlib numpy scipy scikit-learn -y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by loading the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% IMPORTS\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "from scipy.io import loadmat\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "\n",
    "# set global properties for all plots:\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.rcParams[\"axes.spines.top\"]    = False\n",
    "plt.rcParams[\"axes.spines.bottom\"] = False\n",
    "plt.rcParams[\"axes.spines.left\"]   = False\n",
    "plt.rcParams[\"axes.spines.right\"]  = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the path to the data. If you are running this script in a Google Colab environment, you need upload the data file `hypothalamus_calcium_imaging_remedios_et_al.mat` from the GitHub repository to your Google Drive; please follow further instructions [here](https://www.fabriziomusacchio.com/blog/2023-03-23-google_colab_file_access/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "DATA_FILENAME = 'hypothalamus_calcium_imaging_remedios_et_al.mat'\n",
    "DATA_FILE = os.path.join(DATA_PATH, DATA_FILENAME)\n",
    "\n",
    "RESULTSPATH = '../results/'\n",
    "# check whether the results path exists, if not, create it:\n",
    "if not os.path.exists(RESULTSPATH):\n",
    "    os.makedirs(RESULTSPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a helper-function to calculate the silhouette score for each clustering method and plot the according silhouette plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for manually computing the mean silhouette score of a kmeans clustering:\n",
    "def plot_silhouette_score(fitted_model, PCA_model_S3_fit, method='kmeans'):\n",
    "    \n",
    "    # get the cluster labels:\n",
    "    labels = fitted_model.labels_\n",
    "    # labels = agglo_fit.labels_\n",
    "    # labels = kmeans_fit.labels_\n",
    "    n_clusters = len(np.unique(labels))\n",
    "\n",
    "    # compute the silhouette scores for each sample:\n",
    "    silhouette_vals = silhouette_samples(PCA_model_S3_fit, labels)\n",
    "    \"\"\" \n",
    "    With silhouette_samples, we can compute the silhouette score for each sample. The silhouette\n",
    "    score is a measure of how similar an object is to its own cluster (cohesion) compared to other\n",
    "    clusters (separation). The silhouette ranges from -1 to 1, where a high value indicates that the\n",
    "    object is well matched to its own cluster and poorly matched to neighboring clusters. \n",
    "\n",
    "    The silhouette_samples function computes the silhouette coefficient for each sample. The Silhouette \n",
    "    Coefficient is a measure of how well samples are clustered with sample 10 that are similar to \n",
    "    themselves. Clustering models with a high silhouette coefficient are said to be dense, where samples \n",
    "    in the same cluster are similar to each other, and well separated, where samples in different \n",
    "    clusters are not very similar to each other.\n",
    "\n",
    "    The Silhouette Coefficient is calculated using the mean intra-cluster distance (a) and the mean \n",
    "    nearest-cluster distance (b) for each sample. The Silhouette Coefficient for a sample is \n",
    "\n",
    "            (b - a) / max(a, b)). \n",
    "\n",
    "    To clarify, b is the distance between a sample and the nearest cluster that the sample is not a \n",
    "    part of. Note that Silhouette Coefficient is only defined if number of labels is \n",
    "\n",
    "            2 < n_labels < n_samples - 1.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # compute the mean silhouette score:\n",
    "    silhouette_avg = silhouette_score(PCA_model_S3_fit, labels)\n",
    "    print(f\"Mean silhouette score: {silhouette_avg}\")\n",
    "    \"\"\" \n",
    "    silhouette_score returns the mean Silhouette Coefficient over all samples.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a silhouette plot\n",
    "    fig, ax1 = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(7, 6)\n",
    "\n",
    "    ax1.set_xlim([-0.1, 1]) # the silhouette coefficient can range from -1, 1\n",
    "    ax1.set_ylim([0, len(PCA_model_S3_fit) + (n_clusters + 1) * 10])\n",
    "    # the (n_clusters+1)*10 is for inserting blank space between silhouette plots of individual clusters\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # aggregate the silhouette scores for samples belonging to cluster i, and sort them:\n",
    "        ith_cluster_silhouette_vals = silhouette_vals[labels == i]\n",
    "        ith_cluster_silhouette_vals.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_vals.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.viridis(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                        0, ith_cluster_silhouette_vals,\n",
    "                        facecolor=color, edgecolor=color, alpha=1.0)\n",
    "\n",
    "        # label the silhouette plots with their cluster numbers at the middle:\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # compute the new y_lower for next plot:\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # plot a vertical line for the average silhouette score of all the values:\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks(np.arange(-0.1, 1.1, 0.2))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULTSPATH, f'{method} silhouette_plot ({n_clusters} clusters).png'), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% LOAD THE DATA\n",
    "hypothalamus_data = loadmat(DATA_FILE)\n",
    "\n",
    "# Extract the N main data arrays into N separate variables:\n",
    "neural_data   = hypothalamus_data['neural_data']\n",
    "attack_vector = hypothalamus_data['attack_vector']\n",
    "gender_vector = hypothalamus_data['sex_vector']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 Repeat the PCA analysis from the previous script. Perform the PCA for 3 components\n",
    "1. Perform PCA with 3 components.\n",
    "2. Plot the 3 principal components (PCs) in a 3D scatter plot.\n",
    "3. plot the 3 PCs in a three 2D scatter plot (using `subplot`).\n",
    "\n",
    "Useful tip: With `ax.view_init(elev=30, azim=45)`, you can change the view of the 3D plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here:\n",
    "\n",
    "# n_components  =\n",
    "# PCA_model_S10 = \n",
    "\n",
    "\n",
    "# fit the PCA model to the neural data:\n",
    "\n",
    "\n",
    "# Plot the first three principal components in 3D space:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 k-means clustering\n",
    "Apply k-means clustering to the three PCs of the PCAed neural data:\n",
    "\n",
    "1. Start with 2 clusters. \n",
    "2. After the clustering, update the 3D and 2D plots by color-code them with the cluster labels. What do you notice? \n",
    "3. Compare the clustering results with the gender labeled PCAed data from the previous script. What do you notice?\n",
    "4. Compute the silhouette score for the kmeans clustering and interpret the results.\n",
    "5. Repeat all steps for 3 and 6 clusters. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here:\n",
    "\n",
    "# create a kmeans object with n_clusters clusters:\n",
    "# n_clusters=\n",
    "# kmeans    = \n",
    "# kmeans_fit = \n",
    "\n",
    "\n",
    "# verify that kmeans has indeed identified 2 clusters (`kmeans_fit.labels_`):\n",
    "\n",
    "\n",
    "# inspect the cluster centers (`kmeans_fit.cluster_centers_`):\n",
    "\n",
    "\n",
    "# re-plot the 3 PCs, now color-coded by the kmeans cluster labels and with the cluster centers:\n",
    "\n",
    "# also re-plot the 3 PCs in separate 2D subplots, now color-coded by the kmeans cluster labels and with the cluster centers:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here:\n",
    "\n",
    "# plot the silhouette plot by using our helper-function:\n",
    "# plot_silhouette_score(...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answers go here:\n",
    "\n",
    "# Answer to question 2:\n",
    "\n",
    "# Answer to question 3:\n",
    "\n",
    "# Answer to question 4:\n",
    "\n",
    "# Answer to question 5:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 Agglomerative clustering\n",
    "1. Repeat the clustering analysis with agglomerative clustering. Start with 2 clusters.\n",
    "2. Compare with the 2-cluster k-means results and the gender labeled PCAed data. What do you notice?\n",
    "3. Plot the dendrogram of the agglomerative clustering. What do you notice?\n",
    "4. Plot the silhouette plot for the agglomerative clustering. What do you notice?\n",
    "5. Repeat all steps for 3 and 6 clusters. What do you notice?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here:\n",
    "\n",
    "# create an agglomerative clustering object with n_clusters clusters:\n",
    "# n_clusters=2\n",
    "# agglo     =\n",
    "# agglo_fit =\n",
    "\n",
    "\n",
    "\n",
    "# verify that agglo has indeed identified 2 clusters (`agglo_fit.labels_`):\n",
    "\n",
    "\n",
    "# re-plot the 3 PCs, now color-coded with the agglomerative cluster labels:\n",
    "\n",
    "\n",
    "# also re-plot the 3 PCs in separate 2D subplots, now color-coded  with the agglomerative cluster labels:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating and plotting the dendrogram may take a while due to the computation of the linkage matrix. The dendrogram shows the hierarchical clustering of the data. It therefore recalculates the distances between the clusters at each merge and shows the overall structure of the data. The dendrogram needs be created only once and is independent of the later chosen number of clusters.\n",
    "\n",
    "The x-axis shows the samples and the y-axis shows the distance between the clusters. The height of the dendrogram at each merge represents the distance between the two clusters that are merged.\n",
    "\n",
    "The function `linkage` computes the hierarchical clustering of the input data based on the method specified (here: 'ward'). The method 'ward' minimizes the variance of the clusters being merged. The linkage matrix contains the hierarchical clustering encoded as a linkage matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here:\n",
    "\n",
    "# plot the dendrogram:\n",
    "# linkage_matrix = linkage(..., method='ward')\n",
    "#\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "# dendrogram(linkage_matrix, ax=ax)\n",
    "# plt. ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here:\n",
    "\n",
    "# plot the silhouette plot using our helper-function:\n",
    "# plot_silhouette_score(fitted_model=..., PCA_model_S3_fit=..., method=...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answers go here:\n",
    "\n",
    "# Answer to question 2:\n",
    "\n",
    "# Answer to question 3:\n",
    "\n",
    "# Answer to question 4:\n",
    "\n",
    "# Answer to question 5:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 DBSCAN clustering\n",
    "1. Repeat the clustering analysis with DBSCAN. Start with an `eps` of 0.5 and `min_samples? of 5.\n",
    "2. Compare with the previous cluster results. What do you notice?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here:\n",
    "\n",
    "# create a DBSCAN object with eps and min_samples:\n",
    "# eps        =0.5\n",
    "# min_samples=5\n",
    "# dbscan     =\n",
    "# dbscan_fit =\n",
    "\n",
    "\n",
    "# check how many clusters were found (`dbscan_fit.labels_`):\n",
    "\n",
    "\n",
    "# plot the 3 PCs, now color-coded by the DBSCAN cluster labels:\n",
    "\n",
    "\n",
    "# also re-plot the 3 PCs in separate 2D subplots, now color-coded with the DBSCAN cluster labels:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here:\n",
    "\n",
    "# Answer to question 2:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dimredcution",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
